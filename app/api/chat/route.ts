import { OpenAIStream, StreamingTextResponse } from 'ai';
import OpenAI from 'openai';
import { aiService } from '@/lib/ai-service';
import { memoryService } from '@/lib/memory-service';
import { createRouteHandlerClient } from '@supabase/auth-helpers-nextjs';
import { cookies } from 'next/headers';

// Allow streaming responses up to 30 seconds
export const maxDuration = 30;

const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY,
});

export async function POST(req: Request) {
    try {
        const { messages } = await req.json();
        const supabase = createRouteHandlerClient({ cookies });

        // 1. Get User Context (Who am I talking to?)
        let userContext = "";
        try {
            const { data: { session } } = await supabase.auth.getSession();
            if (session?.user) {
                console.log('üß† Loading User Memory for:', session.user.id);
                userContext = await memoryService.getUserContext(session.user.id);
            }
        } catch (ctxError) {
            console.error('‚ö†Ô∏è Failed to load user context:', ctxError);
        }

        // 2. Get the latest user message
        const lastMessage = messages[messages.length - 1];
        const userQuery = lastMessage.content;

        console.log('üí¨ New Chat Query:', userQuery);

        // 3. Search in Knowledge Base (DigitalOcean RAG)
        let knowledgeContext = '';
        try {
            console.log('üïµÔ∏è‚Äç‚ôÇÔ∏è Searching Knowledge Base...');
            const knowledgeChunks = await aiService.searchKnowledgeBase(userQuery, 4); // Top 4 chunks

            if (knowledgeChunks && knowledgeChunks.length > 0) {
                knowledgeContext = knowledgeChunks.map((chunk: any) => chunk.content).join('\n---\n');
                console.log(`‚úÖ Found ${knowledgeChunks.length} relevant chunks.`);
            } else {
                console.log('‚ö†Ô∏è No relevant knowledge found.');
            }
        } catch (searchError) {
            console.error('‚ùå RAG Search Error:', searchError);
        }

        // 4. Construct System Instruction with User + Knowledge Context
        const baseSystemInstruction = `
            Voc√™ √© o Dr. IA, um tutor especialista em Resid√™ncia M√©dica (ENARE, USP, etc).
            
            ### QUEM √â VOC√ä:
            - Um mentor experiente, did√°tico e objetivo.
            - Focado 100% em aprovar o aluno na Resid√™ncia.
            - Usa "pulo do gato", mnem√¥nicos e dicas de prova.

            ### O ALUNO (CONTEXTO):
            ${userContext || "Aluno n√£o identificado."}

            ### DIRETRIZES:
            1. Personalize a resposta: Se o aluno for fraco em um tema, explique do zero. Se for forte, aprofunde.
            2. Se o "CONTE√öDO DE APOIO" for citado abaixo, USE-O como fonte prim√°ria.
            3. Se n√£o houver contexto, use seu conhecimento m√©dico (GPT-4o).
            4. Sempre termine encorajando ou sugerindo uma pr√≥xima pergunta relacionada ao ponto fraco do aluno.
        `.trim();

        const finalSystemInstruction = knowledgeContext
            ? `${baseSystemInstruction}\n\n### CONTE√öDO DE APOIO (Reference Material):\n${knowledgeContext}`
            : baseSystemInstruction;

        // 5. Call OpenAI with Context
        const response = await openai.chat.completions.create({
            model: 'gpt-4o',
            messages: [
                { role: 'system', content: finalSystemInstruction },
                ...messages
            ],
            stream: true,
        });

        // 6. Stream response with Memory Analysis (Agent Observer)
        const stream = OpenAIStream(response as any, {
            onFinal(completion) {
                // Background Task: Analyze conversation for new memories
                // Only if we have a valid user
                supabase.auth.getSession().then(({ data: { session } }) => {
                    if (session?.user?.id) {
                        console.log('üïµÔ∏è [Observer] Analyzing detailed interaction...');
                        memoryService.analyzeAndSaveMemory(session.user.id, userQuery, completion);
                    }
                });
            }
        });
        return new StreamingTextResponse(stream);

    } catch (error) {
        console.error('‚ùå Error in chat API:', error);
        return new Response(JSON.stringify({ error: 'Failed to process chat request' }), { status: 500 });
    }
}
